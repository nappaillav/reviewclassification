{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Accept_2017=pandas.read_excel('./acceptrejectPaperDetails_2017.xlsx',sheetname=\"Accept\");\n",
    "Reject_2017=pandas.read_excel('./acceptrejectPaperDetails_2017.xlsx',sheetname=\"Reject\");\n",
    "Scores_2017=pandas.read_excel('./acceptrejectPaperDetails_2017.xlsx',sheetname=\"Scores\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submission ID</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Factors Affecting the Intelligibility of Low-p...</td>\n",
       "      <td>Frequency compression is an effective alternat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phonetic Restoration of Temporally Reversed Sp...</td>\n",
       "      <td>Early study showed that temporally reversed sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cross-linguistic Distinctions between Professi...</td>\n",
       "      <td>This work  investigates acoustic and perceptua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A comparison of Danish listeners’ processing c...</td>\n",
       "      <td>The present study used a sentence verification...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A new cosine series antialiasing function and ...</td>\n",
       "      <td>We formulated and implemented a procedure to g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Submission ID  Unnamed: 1  \\\n",
       "0              2         NaN   \n",
       "1              4         NaN   \n",
       "2              7         NaN   \n",
       "3              9         NaN   \n",
       "4             15         NaN   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Factors Affecting the Intelligibility of Low-p...   \n",
       "1  Phonetic Restoration of Temporally Reversed Sp...   \n",
       "2  Cross-linguistic Distinctions between Professi...   \n",
       "3  A comparison of Danish listeners’ processing c...   \n",
       "4  A new cosine series antialiasing function and ...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Frequency compression is an effective alternat...  \n",
       "1  Early study showed that temporally reversed sp...  \n",
       "2  This work  investigates acoustic and perceptua...  \n",
       "3  The present study used a sentence verification...  \n",
       "4  We formulated and implemented a procedure to g...  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accept_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 794 entries, 0 to 793\n",
      "Data columns (total 5 columns):\n",
      "Submission ID    794 non-null int64\n",
      "Title            794 non-null object\n",
      "Abstract         793 non-null object\n",
      "result           794 non-null int64\n",
      "mean             794 non-null float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 31.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 677 entries, 0 to 676\n",
      "Data columns (total 5 columns):\n",
      "Submission ID    677 non-null int64\n",
      "Title            677 non-null object\n",
      "Abstract         677 non-null object\n",
      "result           677 non-null int64\n",
      "mean             677 non-null float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 26.5+ KB\n"
     ]
    }
   ],
   "source": [
    "Accept_2017.drop(['Unnamed: 1'],axis=1,inplace=True)\n",
    "Accept_2017[\"result\"]=pandas.Series(np.zeros(len(Accept_2017),dtype=int)) \n",
    "Accept_2017[\"mean\"]=pandas.Series(np.zeros(len(Accept_2017),dtype=float)) \n",
    "Accept_2017.info()\n",
    "Reject_2017.drop(['Unnamed: 1'],axis=1,inplace=True)\n",
    "Reject_2017[\"result\"]=pandas.Series(np.ones(len(Reject_2017),dtype=int)) \n",
    "Reject_2017[\"mean\"]=pandas.Series(np.zeros(len(Reject_2017),dtype=float)) \n",
    "Reject_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_rej = pandas.merge(Scores_2017,Reject_2017[['Submission ID','Title','Abstract','result','mean']]\n",
    "                 ,on='Submission ID')\n",
    "result_acc = pandas.merge(Scores_2017,Accept_2017[['Submission ID','Title','Abstract','result','mean']]\n",
    "                 ,on='Submission ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_2017 = result_acc.append(result_rej, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_toscore(temp):\n",
    "    temp = temp.split()\n",
    "    score = [float(i) for i in temp]\n",
    "    m = np.mean(score)\n",
    "    s = np.std(score)\n",
    "    return score,m,s\n",
    "#Reject_2017.head()\n",
    "for i in result_2017.index:\n",
    "    #print(i)\n",
    "    temp = result_2017.iloc[i][\"Scores\"]\n",
    "    #print(temp)\n",
    "    score,m,s = text_toscore(temp) \n",
    "    #print(m)\n",
    "    result_2017.at[i, 'mean'] = m\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submission ID</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>result</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1409</td>\n",
       "      <td>4.95    5.65    5.70    6</td>\n",
       "      <td>What do babies hear? Analyses of child- and ad...</td>\n",
       "      <td>Child-directed speech is argued to facilitate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>1452</td>\n",
       "      <td>5.05    5.60    5.95    6</td>\n",
       "      <td>Tacotron: Towards End-To-End Speech Synthesis</td>\n",
       "      <td>A text-to-speech synthesis system typically co...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>137</td>\n",
       "      <td>5.15    5.80    5.80    5.85</td>\n",
       "      <td>A Generative Model for Score Normalization in ...</td>\n",
       "      <td>We propose a theoretical framework for thinkin...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1111</td>\n",
       "      <td>4.90    5.80    6    6</td>\n",
       "      <td>The ASVspoof 2017 Challenge: Assessing the Lim...</td>\n",
       "      <td>The ASVspoof initiative was created to promote...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>1746</td>\n",
       "      <td>5.05    5.90    6    6</td>\n",
       "      <td>Effects of Talker Dialect, Gender &amp; Race Diffe...</td>\n",
       "      <td>This project compares the accuracy of two auto...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.7375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Submission ID                            Scores  \\\n",
       "641           1409     4.95    5.65    5.70    6       \n",
       "664           1452     5.05    5.60    5.95    6       \n",
       "65             137  5.15    5.80    5.80    5.85       \n",
       "500           1111        4.90    5.80    6    6       \n",
       "780           1746        5.05    5.90    6    6       \n",
       "\n",
       "                                                 Title  \\\n",
       "641  What do babies hear? Analyses of child- and ad...   \n",
       "664      Tacotron: Towards End-To-End Speech Synthesis   \n",
       "65   A Generative Model for Score Normalization in ...   \n",
       "500  The ASVspoof 2017 Challenge: Assessing the Lim...   \n",
       "780  Effects of Talker Dialect, Gender & Race Diffe...   \n",
       "\n",
       "                                              Abstract  result    mean  \n",
       "641  Child-directed speech is argued to facilitate ...       0  5.5750  \n",
       "664  A text-to-speech synthesis system typically co...       0  5.6500  \n",
       "65   We propose a theoretical framework for thinkin...       0  5.6500  \n",
       "500  The ASVspoof initiative was created to promote...       0  5.6750  \n",
       "780  This project compares the accuracy of two auto...       0  5.7375  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(result_2017.sort_values[])\n",
    "result_2017 = result_2017.fillna(\"\")\n",
    "data = result_2017.sort_values(by=['mean'])\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reject = result_rej.values.tolist()\n",
    "accept = result_acc.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.15, 3.15, 4.95]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4166666666666665"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2017 = result_acc.append(result_rej, ignore_index=True)\n",
    "temp = result_2017.iloc[1467][\"Scores\"]\n",
    "temp = temp.split()\n",
    "print([float(i) for i in temp])\n",
    "np.mean([float(i) for i in temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2017 = result_2017.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('Submission ID', 'Scores')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a50eb496934a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_2017\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Submission ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2017\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Submission ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: ('Submission ID', 'Scores')"
     ]
    }
   ],
   "source": [
    "test = data_2017['Submission ID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valliappan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:\n",
      "b'/tmp/try_flags_b17bg2cr.c:4:19: fatal error: cudnn.h: No such file or directory\\ncompilation terminated.\\n'\n",
      "Mapped name None to device cuda: GeForce GTX 1050 Ti (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1471"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=result_2017.Abstract\n",
    "Y=result_2017.result\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " '2.40    3.35    5    5.45    ',\n",
       " 'The Effects of Sonority and Preceding Vowels on the Distribution of Singleton/Geminate Consonants in Spoken Japanese',\n",
       " 'By studying the Corpus of Spontaneous Japanese (hereafter CSJ) [1], this\\nproject offers new findings concerning patterns in the distribution of\\nsingleton and geminate consonants in spontaneous speech. In particular, the\\ncurrent study reports on the details of the distribution of singletons and\\ngeminates in actual speech. It also examines the effect of the segmental\\nproperties of singletons and geminates, such as manner of articulation, and the\\neffect of preceding vowels.\\nThe current study brought forth the following findings that would be difficult\\nto observe by other approaches, such as traditional (i.e., intuition-based and\\ndictionary-based) studies and perception experiments. The patterns in the\\ndistribution and phonetic properties of singletons and geminates greatly differ\\naccording to place, manner, and voicing. Specifically, the distribution of\\ngeminates follows the sonority hierarchy; namely, a less sonorous sound is more\\ncompatible with a geminate. Additionally, the distribution is affected by\\npreceding vowels: although preceding vowels are longer before geminates than\\nsingletons, the duration of the preceding vowels is inversely proportional to\\nthe duration of the singleton-geminate ratio, suggesting the trade-off between\\ncues, while longer vowels tend to attract more geminates. The study also\\nuncovered hitherto unnoticed aspects, such as fricative, affricate, and nasal\\ngeminates.',\n",
       " 0,\n",
       " [2.4, 3.35, 5.0, 5.45],\n",
       " 4.05,\n",
       " 1.2323757543866238]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i =[]\n",
    "i = reject[0]\n",
    "i.append(0)\n",
    "i.append([float(num) for num in i[1].split()])\n",
    "i.append(np.mean(i[5]))\n",
    "i.append(np.std(i[5]))\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list = []\n",
    "list_2 = []\n",
    "le = LabelEncoder()\n",
    "dictionary = {}\n",
    "for i in accept:\n",
    "    j = []\n",
    "    i.append(1)\n",
    "    i.append([float(num) for num in i[1].split()])\n",
    "    i.append(np.mean(i[5]))\n",
    "    i.append(np.std(i[5]))\n",
    "    list.append(i)\n",
    "    j.append(i[0])\n",
    "    j.append(i[4])\n",
    "    j.append(i[5])\n",
    "    j.append(i[6])\n",
    "    j.append(i[7])\n",
    "    \n",
    "    list_2.append(j)\n",
    "    #line = [float(num) for num in i[1].split()]\n",
    "for i in reject:\n",
    "    j=[]\n",
    "    i.append(0)\n",
    "    i.append([float(num) for num in i[1].split()])\n",
    "    i.append(np.mean(i[5]))\n",
    "    i.append(np.std(i[5]))\n",
    "    list.append(i)\n",
    "    j.append(i[0])\n",
    "    j.append(i[4])\n",
    "    j.append(i[5])\n",
    "    j.append(i[6])\n",
    "    j.append(i[7])\n",
    "    list_2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 4000\n",
    "max_len = 200\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1471 entries, 0 to 1470\n",
      "Data columns (total 6 columns):\n",
      "Submission ID    1471 non-null int64\n",
      "Scores           1471 non-null object\n",
      "Title            1471 non-null object\n",
      "Abstract         1471 non-null object\n",
      "result           1471 non-null int64\n",
      "mean             1471 non-null float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 69.0+ KB\n"
     ]
    }
   ],
   "source": [
    "result_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           200000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 246,337\n",
      "Trainable params: 246,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok.fit_on_texts(X_test)\n",
    "sequences_test = tok.texts_to_sequences(X_test)\n",
    "sequences_matrix_test = sequence.pad_sequences(sequences_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1250 samples, validate on 221 samples\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0217 - acc: 0.9968 - val_loss: 2.5563 - val_acc: 0.4751\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.6520 - val_acc: 0.4932\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.9194 - val_acc: 0.4887\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 7.8005e-04 - acc: 1.0000 - val_loss: 3.1296 - val_acc: 0.4932\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.2496e-04 - acc: 1.0000 - val_loss: 3.2532 - val_acc: 0.5204\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.1876e-04 - acc: 1.0000 - val_loss: 3.5539 - val_acc: 0.5204\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 9.0757e-05 - acc: 1.0000 - val_loss: 3.9481 - val_acc: 0.4977\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.9540e-05 - acc: 1.0000 - val_loss: 4.1285 - val_acc: 0.5158\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.4329e-05 - acc: 1.0000 - val_loss: 4.2358 - val_acc: 0.4796\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.5671 - acc: 0.8064 - val_loss: 2.4720 - val_acc: 0.4706\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0272 - acc: 0.9920 - val_loss: 2.5740 - val_acc: 0.4570\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0099 - acc: 0.9992 - val_loss: 2.7572 - val_acc: 0.4615\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0066 - acc: 0.9992 - val_loss: 2.8760 - val_acc: 0.4796\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 3.1399 - val_acc: 0.4796\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 9.3107e-04 - acc: 1.0000 - val_loss: 3.3462 - val_acc: 0.4932\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.9484e-04 - acc: 1.0000 - val_loss: 3.5352 - val_acc: 0.4977\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4759e-04 - acc: 1.0000 - val_loss: 3.7033 - val_acc: 0.5113\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 8.9520e-05 - acc: 1.0000 - val_loss: 3.8612 - val_acc: 0.5068\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.8247e-05 - acc: 1.0000 - val_loss: 4.0424 - val_acc: 0.4977\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.8314e-05 - acc: 1.0000 - val_loss: 4.2096 - val_acc: 0.5068\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.5836e-05 - acc: 1.0000 - val_loss: 4.3474 - val_acc: 0.5023\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.2296e-05 - acc: 1.0000 - val_loss: 4.4686 - val_acc: 0.4932\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.0782e-06 - acc: 1.0000 - val_loss: 4.6239 - val_acc: 0.4887\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 3.7816e-06 - acc: 1.0000 - val_loss: 4.6786 - val_acc: 0.4977\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.8537e-06 - acc: 1.0000 - val_loss: 4.9778 - val_acc: 0.4887\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0203e-06 - acc: 1.0000 - val_loss: 5.1035 - val_acc: 0.4932\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 8.9236e-07 - acc: 1.0000 - val_loss: 5.2459 - val_acc: 0.4932\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.9962e-07 - acc: 1.0000 - val_loss: 5.1994 - val_acc: 0.4842\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.3507e-07 - acc: 1.0000 - val_loss: 5.2852 - val_acc: 0.4932\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 3.0727e-07 - acc: 1.0000 - val_loss: 5.4607 - val_acc: 0.4977\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.6707e-07 - acc: 1.0000 - val_loss: 4.9249 - val_acc: 0.5385\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.0021 - acc: 0.6200 - val_loss: 7.9834 - val_acc: 0.4480\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.3327 - acc: 0.9616 - val_loss: 3.2342 - val_acc: 0.4932\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0047 - acc: 0.9992 - val_loss: 3.2891 - val_acc: 0.4932\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 3.3306 - val_acc: 0.4977\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 3.3993 - val_acc: 0.4932\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 7.8452e-04 - acc: 1.0000 - val_loss: 3.4735 - val_acc: 0.4842\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.8058e-04 - acc: 1.0000 - val_loss: 3.5658 - val_acc: 0.4887\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.8350e-04 - acc: 1.0000 - val_loss: 3.6744 - val_acc: 0.4842\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.6744e-04 - acc: 1.0000 - val_loss: 3.7698 - val_acc: 0.4796\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 9.5495e-05 - acc: 1.0000 - val_loss: 3.8827 - val_acc: 0.4932\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 5.2324e-05 - acc: 1.0000 - val_loss: 3.9859 - val_acc: 0.5023\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.5850e-05 - acc: 1.0000 - val_loss: 4.0819 - val_acc: 0.5113\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.7745e-05 - acc: 1.0000 - val_loss: 4.2176 - val_acc: 0.5158\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 8.4943e-06 - acc: 1.0000 - val_loss: 4.3155 - val_acc: 0.5158\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.6480e-06 - acc: 1.0000 - val_loss: 4.4248 - val_acc: 0.5204\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.4432e-06 - acc: 1.0000 - val_loss: 4.5915 - val_acc: 0.5158\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.6550e-06 - acc: 1.0000 - val_loss: 4.6937 - val_acc: 0.5068\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 7.5665e-07 - acc: 1.0000 - val_loss: 4.8007 - val_acc: 0.4932\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 5.6980e-07 - acc: 1.0000 - val_loss: 4.9159 - val_acc: 0.4977\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 4.2594e-07 - acc: 1.0000 - val_loss: 5.0326 - val_acc: 0.4932\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 3.2362e-07 - acc: 1.0000 - val_loss: 5.1655 - val_acc: 0.4932\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.5725e-07 - acc: 1.0000 - val_loss: 5.2736 - val_acc: 0.4977\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7735e-07 - acc: 1.0000 - val_loss: 5.3493 - val_acc: 0.4887\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.6286e-07 - acc: 1.0000 - val_loss: 5.4631 - val_acc: 0.4932\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.5135e-07 - acc: 1.0000 - val_loss: 5.5810 - val_acc: 0.4932\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5007e-07 - acc: 1.0000 - val_loss: 5.6082 - val_acc: 0.4887\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.2781e-07 - acc: 1.0000 - val_loss: 5.5958 - val_acc: 0.4842\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.3014e-07 - acc: 1.0000 - val_loss: 5.6017 - val_acc: 0.4977\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1694e-07 - acc: 1.0000 - val_loss: 5.9716 - val_acc: 0.4887\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0218 - acc: 0.9960 - val_loss: 4.1883 - val_acc: 0.4796\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 4.3701 - val_acc: 0.4977\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4429e-04 - acc: 1.0000 - val_loss: 4.4442 - val_acc: 0.4977\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 7.9925e-05 - acc: 1.0000 - val_loss: 4.5449 - val_acc: 0.4977\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 5.2037e-05 - acc: 1.0000 - val_loss: 4.6104 - val_acc: 0.5023\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.6428e-05 - acc: 1.0000 - val_loss: 4.7427 - val_acc: 0.4887\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.8259e-05 - acc: 1.0000 - val_loss: 4.8052 - val_acc: 0.4932\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 8.7883e-06 - acc: 1.0000 - val_loss: 4.9043 - val_acc: 0.4977\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 5.0247e-06 - acc: 1.0000 - val_loss: 4.9719 - val_acc: 0.4932\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.7256e-06 - acc: 1.0000 - val_loss: 5.0519 - val_acc: 0.5113\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.8823e-06 - acc: 1.0000 - val_loss: 5.1029 - val_acc: 0.5113\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1649e-06 - acc: 1.0000 - val_loss: 5.1941 - val_acc: 0.5068\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.7165e-07 - acc: 1.0000 - val_loss: 5.2474 - val_acc: 0.5023\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.8807e-07 - acc: 1.0000 - val_loss: 5.3285 - val_acc: 0.5023\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.0642e-07 - acc: 1.0000 - val_loss: 5.4538 - val_acc: 0.4977\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.0368e-07 - acc: 1.0000 - val_loss: 5.5012 - val_acc: 0.4932\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.8356e-07 - acc: 1.0000 - val_loss: 5.4892 - val_acc: 0.4932\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.5293e-07 - acc: 1.0000 - val_loss: 5.5740 - val_acc: 0.4887\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.5582e-07 - acc: 1.0000 - val_loss: 5.6272 - val_acc: 0.5023\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.2940e-07 - acc: 1.0000 - val_loss: 5.6804 - val_acc: 0.5068\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1892e-07 - acc: 1.0000 - val_loss: 5.6766 - val_acc: 0.5068\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.2961e-07 - acc: 1.0000 - val_loss: 5.6898 - val_acc: 0.5113\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.1153e-07 - acc: 1.0000 - val_loss: 5.7339 - val_acc: 0.5113\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1870e-07 - acc: 1.0000 - val_loss: 5.6191 - val_acc: 0.5068\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1501e-07 - acc: 1.0000 - val_loss: 5.7580 - val_acc: 0.5113\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1011e-07 - acc: 1.0000 - val_loss: 5.7665 - val_acc: 0.5113\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1727e-07 - acc: 1.0000 - val_loss: 5.8237 - val_acc: 0.5113\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.1101e-07 - acc: 1.0000 - val_loss: 5.9593 - val_acc: 0.5113\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1010e-07 - acc: 1.0000 - val_loss: 5.8653 - val_acc: 0.5204\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1179e-07 - acc: 1.0000 - val_loss: 6.2105 - val_acc: 0.4796\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1087e-07 - acc: 1.0000 - val_loss: 5.6833 - val_acc: 0.5204\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1005e-07 - acc: 1.0000 - val_loss: 6.0245 - val_acc: 0.5113\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.1087e-07 - acc: 1.0000 - val_loss: 5.9888 - val_acc: 0.5158\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.1384e-07 - acc: 1.0000 - val_loss: 5.8608 - val_acc: 0.5113\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0921e-07 - acc: 1.0000 - val_loss: 5.8446 - val_acc: 0.5113\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1105e-07 - acc: 1.0000 - val_loss: 6.0361 - val_acc: 0.5158\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.1043e-07 - acc: 1.0000 - val_loss: 5.9437 - val_acc: 0.5204\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.3712 - acc: 0.9760 - val_loss: 5.3163 - val_acc: 0.5339\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0971e-06 - acc: 1.0000 - val_loss: 5.5283 - val_acc: 0.5023\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.4955e-07 - acc: 1.0000 - val_loss: 5.5711 - val_acc: 0.5023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f110f695f98>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=100,validation_data=(sequences_matrix_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_new = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1471, 10687)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1250 samples, validate on 221 samples\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.6920 - acc: 0.5320 - val_loss: 0.6880 - val_acc: 0.5566\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.7006 - acc: 0.5368 - val_loss: 0.6885 - val_acc: 0.5566\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.6739 - acc: 0.5544 - val_loss: 0.6886 - val_acc: 0.5566\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.6357 - acc: 0.7520 - val_loss: 0.6893 - val_acc: 0.5385\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.5850 - acc: 0.7640 - val_loss: 0.7227 - val_acc: 0.5068\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.4526 - acc: 0.8808 - val_loss: 0.7508 - val_acc: 0.5204\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.3293 - acc: 0.9040 - val_loss: 0.8747 - val_acc: 0.5520\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.2182 - acc: 0.9368 - val_loss: 1.0212 - val_acc: 0.5339\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.1561 - acc: 0.9560 - val_loss: 1.3663 - val_acc: 0.5204\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.1226 - acc: 0.9560 - val_loss: 1.2881 - val_acc: 0.5294\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0737 - acc: 0.9832 - val_loss: 1.9962 - val_acc: 0.5068\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0732 - acc: 0.9768 - val_loss: 1.7772 - val_acc: 0.5520\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0198 - acc: 0.9976 - val_loss: 2.1834 - val_acc: 0.5113\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0130 - acc: 0.9976 - val_loss: 2.5618 - val_acc: 0.5249\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0073 - acc: 0.9992 - val_loss: 2.6782 - val_acc: 0.4932\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.1047 - acc: 0.9632 - val_loss: 2.1293 - val_acc: 0.5113\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0088 - acc: 0.9992 - val_loss: 2.4091 - val_acc: 0.5023\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 2.6400 - val_acc: 0.5023\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.9198 - val_acc: 0.4977\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 8.5272e-04 - acc: 1.0000 - val_loss: 3.1834 - val_acc: 0.4977\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.9335e-04 - acc: 1.0000 - val_loss: 3.4659 - val_acc: 0.4977\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.3563e-04 - acc: 1.0000 - val_loss: 3.7870 - val_acc: 0.4977\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1965e-04 - acc: 1.0000 - val_loss: 4.0327 - val_acc: 0.4932\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 7.2521e-05 - acc: 1.0000 - val_loss: 4.2719 - val_acc: 0.4887\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.4332e-05 - acc: 1.0000 - val_loss: 4.5622 - val_acc: 0.5023\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.1108e-05 - acc: 1.0000 - val_loss: 4.8040 - val_acc: 0.4977\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0105e-05 - acc: 1.0000 - val_loss: 5.0192 - val_acc: 0.4977\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 7.5134e-06 - acc: 1.0000 - val_loss: 5.1464 - val_acc: 0.4977\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.7673e-06 - acc: 1.0000 - val_loss: 5.2457 - val_acc: 0.5023\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.7145e-06 - acc: 1.0000 - val_loss: 5.4886 - val_acc: 0.5158\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0193e-06 - acc: 1.0000 - val_loss: 5.5601 - val_acc: 0.5068\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 9.9022e-07 - acc: 1.0000 - val_loss: 5.8344 - val_acc: 0.5023\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.6072e-07 - acc: 1.0000 - val_loss: 4.8080 - val_acc: 0.5475\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.3406 - acc: 0.9616 - val_loss: 3.6948 - val_acc: 0.5113\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 3.8109 - val_acc: 0.5113\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.6900e-04 - acc: 1.0000 - val_loss: 3.9024 - val_acc: 0.5158\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 5.1307e-04 - acc: 1.0000 - val_loss: 4.0136 - val_acc: 0.5158\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.0124e-04 - acc: 1.0000 - val_loss: 4.1229 - val_acc: 0.5158\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.9437e-04 - acc: 1.0000 - val_loss: 4.2425 - val_acc: 0.5158\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1910e-04 - acc: 1.0000 - val_loss: 4.3634 - val_acc: 0.5113\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 7.5838e-05 - acc: 1.0000 - val_loss: 4.4943 - val_acc: 0.5158\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.6780e-05 - acc: 1.0000 - val_loss: 4.6234 - val_acc: 0.5023\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.5745e-05 - acc: 1.0000 - val_loss: 4.7473 - val_acc: 0.5023\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4806e-05 - acc: 1.0000 - val_loss: 4.8825 - val_acc: 0.4977\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 9.9325e-06 - acc: 1.0000 - val_loss: 5.0362 - val_acc: 0.4977\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.7140e-06 - acc: 1.0000 - val_loss: 5.1444 - val_acc: 0.5023\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.0070e-06 - acc: 1.0000 - val_loss: 5.2603 - val_acc: 0.5068\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.7878e-06 - acc: 1.0000 - val_loss: 5.3504 - val_acc: 0.5068\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.1363e-06 - acc: 1.0000 - val_loss: 5.4334 - val_acc: 0.5023\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 7.9050e-07 - acc: 1.0000 - val_loss: 5.5264 - val_acc: 0.4932\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 5.1956e-07 - acc: 1.0000 - val_loss: 5.5866 - val_acc: 0.4932\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 3.9218e-07 - acc: 1.0000 - val_loss: 5.6968 - val_acc: 0.4977\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.2583e-07 - acc: 1.0000 - val_loss: 5.7810 - val_acc: 0.4887\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1956e-07 - acc: 1.0000 - val_loss: 5.8431 - val_acc: 0.4887\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.0170e-07 - acc: 1.0000 - val_loss: 5.8790 - val_acc: 0.4977\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.7621e-07 - acc: 1.0000 - val_loss: 5.9058 - val_acc: 0.4977\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0121 - acc: 0.9960 - val_loss: 5.7488 - val_acc: 0.5113\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.7074e-06 - acc: 1.0000 - val_loss: 5.7810 - val_acc: 0.4977\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.3596e-06 - acc: 1.0000 - val_loss: 5.7980 - val_acc: 0.4977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 7.0930e-07 - acc: 1.0000 - val_loss: 5.8049 - val_acc: 0.5023\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 5.5399e-07 - acc: 1.0000 - val_loss: 5.8109 - val_acc: 0.5023\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.9803e-07 - acc: 1.0000 - val_loss: 5.8171 - val_acc: 0.4977\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.3224e-07 - acc: 1.0000 - val_loss: 5.8353 - val_acc: 0.4977\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.4623e-07 - acc: 1.0000 - val_loss: 5.8480 - val_acc: 0.4932\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.8576e-07 - acc: 1.0000 - val_loss: 5.8602 - val_acc: 0.4932\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.5690e-07 - acc: 1.0000 - val_loss: 5.8780 - val_acc: 0.4977\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.5309e-07 - acc: 1.0000 - val_loss: 5.9096 - val_acc: 0.5068\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.4789e-07 - acc: 1.0000 - val_loss: 5.9380 - val_acc: 0.5068\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.9876e-07 - acc: 1.0000 - val_loss: 5.9526 - val_acc: 0.5068\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.8721e-07 - acc: 1.0000 - val_loss: 6.0093 - val_acc: 0.4932\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.7206e-07 - acc: 1.0000 - val_loss: 6.0390 - val_acc: 0.5068\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.5717e-07 - acc: 1.0000 - val_loss: 6.0833 - val_acc: 0.4932\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4173e-07 - acc: 1.0000 - val_loss: 6.0673 - val_acc: 0.5023\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4411e-07 - acc: 1.0000 - val_loss: 6.0947 - val_acc: 0.5068\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.2676e-07 - acc: 1.0000 - val_loss: 6.1217 - val_acc: 0.4887\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.2439e-07 - acc: 1.0000 - val_loss: 6.1518 - val_acc: 0.5023\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0281 - acc: 0.9920 - val_loss: 5.1977 - val_acc: 0.5204\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0014 - acc: 0.9992 - val_loss: 5.3674 - val_acc: 0.5068\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.9807e-06 - acc: 1.0000 - val_loss: 5.3797 - val_acc: 0.5023\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.6819e-06 - acc: 1.0000 - val_loss: 5.3857 - val_acc: 0.5068\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.9800e-06 - acc: 1.0000 - val_loss: 5.3909 - val_acc: 0.5068\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.7957e-06 - acc: 1.0000 - val_loss: 5.4027 - val_acc: 0.5068\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 3.6350e-06 - acc: 1.0000 - val_loss: 5.4020 - val_acc: 0.5023\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 3.0189e-06 - acc: 1.0000 - val_loss: 5.4307 - val_acc: 0.5023\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.9924e-06 - acc: 1.0000 - val_loss: 5.4619 - val_acc: 0.5023\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.6064e-06 - acc: 1.0000 - val_loss: 5.4906 - val_acc: 0.5023\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.7686e-06 - acc: 1.0000 - val_loss: 5.5386 - val_acc: 0.4977\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0252e-06 - acc: 1.0000 - val_loss: 5.5541 - val_acc: 0.5023\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0378e-06 - acc: 1.0000 - val_loss: 5.5894 - val_acc: 0.4977\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 7.5220e-07 - acc: 1.0000 - val_loss: 5.6443 - val_acc: 0.5068\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 5.2539e-07 - acc: 1.0000 - val_loss: 5.6916 - val_acc: 0.5068\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.8870e-07 - acc: 1.0000 - val_loss: 5.7300 - val_acc: 0.5068\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.2502e-07 - acc: 1.0000 - val_loss: 5.7962 - val_acc: 0.4977\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2254e-07 - acc: 1.0000 - val_loss: 5.8481 - val_acc: 0.4977\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.8712e-07 - acc: 1.0000 - val_loss: 5.9208 - val_acc: 0.4977\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4797e-07 - acc: 1.0000 - val_loss: 5.9761 - val_acc: 0.5068\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.5609e-07 - acc: 1.0000 - val_loss: 6.0299 - val_acc: 0.5068\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.2921e-07 - acc: 1.0000 - val_loss: 6.0508 - val_acc: 0.4977\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.2463e-07 - acc: 1.0000 - val_loss: 6.0942 - val_acc: 0.4977\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.3234e-07 - acc: 1.0000 - val_loss: 6.1430 - val_acc: 0.5023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1109b35908>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_new,Y,test_size=0.15)\n",
    "\n",
    "model = RNN()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=100,validation_data=(sequences_matrix_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary len: 10447\n",
      "Longest word: methylenedioxymethamphetamine\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# max_df\n",
    "vect = TfidfVectorizer(max_df=100).fit(X)\n",
    "print('Vocabulary len:', len(vect.get_feature_names()))\n",
    "print('Longest word:', max(vect.vocabulary_, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_vect = vect.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1471, 10447)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_vect,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.09%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(Y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 5), analyzer='char_wb').fit(X)\n",
    "X_vect = vect.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562209461791311\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf_svm,X_vect,Y, cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = result_2017.Scores\n",
    "Y = result_2017.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = np.zeros((len(X),11))\n",
    "count = 0\n",
    "addon = 0\n",
    "\n",
    "for i in X:\n",
    "    \n",
    "    X_new[count,addon+0] = i[i.nonzero()].mean()\n",
    "    X_new[count,addon+1] = i[i.nonzero()].std()\n",
    "    temp = np.ptp(i[i.nonzero()])\n",
    "    if(temp == 0):\n",
    "        X_new[count,addon+2] = np.max(X_new[:,addon+2])\n",
    "    else:\n",
    "        X_new[count,addon+2] = X_new[count,addon+0]*(1.0/(temp+0.00001))\n",
    "    a = i\n",
    "    X_new[count,addon+3] = np.sum(np.logical_and(a>0.1, a<=1))\n",
    "    X_new[count,addon+4] = np.sum(np.logical_and(a>1, a<=2))\n",
    "    X_new[count,addon+5] = np.sum(np.logical_and(a>2, a<=3))\n",
    "    X_new[count,addon+6] = np.sum(np.logical_and(a>3, a<=4))\n",
    "    X_new[count,addon+7] = np.sum(np.logical_and(a>4, a<=5))\n",
    "    X_new[count,addon+8] = np.sum(np.logical_and(a>5, a<=6))\n",
    "    X_new[count,addon+9] = np.max(i[i.nonzero()])\n",
    "    X_new[count,addon+10] = np.min(i[i.nonzero()])\n",
    "    count +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4    4.15    4.65    4.85    '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_toscore(temp):\n",
    "    temp = temp.split()\n",
    "    score = [float(i) for i in temp]\n",
    "    #m = np.mean(score)\n",
    "    #s = np.std(score)\n",
    "    return score#,m,s\n",
    "\n",
    "for i in X:\n",
    "    #print(i)\n",
    "    temp = result_2017.iloc[i][\"Scores\"]\n",
    "    #print(temp)\n",
    "    score,m,s = text_toscore(temp) \n",
    "    #print(m)\n",
    "    result_2017.at[i, 'mean'] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    if line:\n",
    "        line = [float(i) for i in line]\n",
    "        polyShape.append(line)\n",
    "\n",
    "\n",
    "    X = np.zeros((len(polyShape),6))\n",
    "    count = 0\n",
    "    for i in polyShape:\n",
    "        temp=np.array(i)\n",
    "        #print(len(temp))\n",
    "        X[count,0:len(temp)] = temp[0:len(temp)]\n",
    "        count +=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_toscore(temp):\n",
    "    temp = temp.split()\n",
    "    score = [float(i) for i in temp]\n",
    "    #m = np.mean(score)\n",
    "    #s = np.std(score)\n",
    "    return score#,m,s\n",
    "\n",
    "X_scores = np.zeros((len(X),6))\n",
    "count =0\n",
    "for i in X:\n",
    "    score = text_toscore(i) \n",
    "    X_scores[count,0:len(score)] = score\n",
    "    count+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1471,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.zeros((len(X_scores),11))\n",
    "count = 0\n",
    "addon = 0\n",
    "\n",
    "for i in X_scores:\n",
    "    \n",
    "    X_new[count,addon+0] = i[i.nonzero()].mean()\n",
    "    X_new[count,addon+1] = i[i.nonzero()].std()\n",
    "    temp = np.ptp(i[i.nonzero()])\n",
    "    if(temp == 0):\n",
    "        X_new[count,addon+2] = np.max(X_new[:,addon+2])\n",
    "    else:\n",
    "        X_new[count,addon+2] = X_new[count,addon+0]*(1.0/(temp+0.00001))\n",
    "    a = i\n",
    "    X_new[count,addon+3] = np.sum(np.logical_and(a>0.1, a<=1))\n",
    "    X_new[count,addon+4] = np.sum(np.logical_and(a>1, a<=2))\n",
    "    X_new[count,addon+5] = np.sum(np.logical_and(a>2, a<=3))\n",
    "    X_new[count,addon+6] = np.sum(np.logical_and(a>3, a<=4))\n",
    "    X_new[count,addon+7] = np.sum(np.logical_and(a>4, a<=5))\n",
    "    X_new[count,addon+8] = np.sum(np.logical_and(a>5, a<=6))\n",
    "    X_new[count,addon+9] = np.max(i[i.nonzero()])\n",
    "    X_new[count,addon+10] = np.min(i[i.nonzero()])\n",
    "    count +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "X_accepted = util.read_textfile('acceptscores.txt')\n",
    "X_rejection =  util.read_textfile('rejectscores.txt')\n",
    "Y_accepted = np.zeros((len(X_accepted),))\n",
    "Y_rejection = np.ones((len(X_rejection),))\n",
    "\n",
    "X_2018 = np.vstack((X_accepted,X_rejection))\n",
    "Y_2018 = np.hstack((Y_accepted,Y_rejection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1331,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1331, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new_2018 = np.zeros((len(X_2018),11))\n",
    "count = 0\n",
    "addon = 0\n",
    "\n",
    "for i in X_2018:\n",
    "    \n",
    "    X_new[count,addon+0] = i[i.nonzero()].mean()\n",
    "    X_new[count,addon+1] = i[i.nonzero()].std()\n",
    "    temp = np.ptp(i[i.nonzero()])\n",
    "    if(temp == 0):\n",
    "        X_new[count,addon+2] = np.max(X_new[:,addon+2])\n",
    "    else:\n",
    "        X_new[count,addon+2] = X_new[count,addon+0]*(1.0/(temp+0.00001))\n",
    "    a = i\n",
    "    X_new[count,addon+3] = np.sum(np.logical_and(a>0.1, a<=1))\n",
    "    X_new[count,addon+4] = np.sum(np.logical_and(a>1, a<=2))\n",
    "    X_new[count,addon+5] = np.sum(np.logical_and(a>2, a<=3))\n",
    "    X_new[count,addon+6] = np.sum(np.logical_and(a>3, a<=4))\n",
    "    X_new[count,addon+7] = np.sum(np.logical_and(a>4, a<=5))\n",
    "    X_new[count,addon+8] = np.sum(np.logical_and(a>5, a<=6))\n",
    "    X_new[count,addon+9] = np.max(i[i.nonzero()])\n",
    "    X_new[count,addon+10] = np.min(i[i.nonzero()])\n",
    "    count +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1331, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43726521412471825"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200,n_jobs=-1)\n",
    "clf.fit(X_new[:,0:2],Y)\n",
    "clf.score(X_new_2018[:,0:2], Y_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 749],\n",
       "       [  0, 582]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel='linear', C=1)\n",
    "clf_svm.fit(X_new,Y.T)\n",
    "y_pred=clf_svm.predict(X_new_2018)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_2018, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43726521412471825"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_2018)/len(Y_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43726521412471825"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_neigh = KNeighborsClassifier(n_neighbors=45)\n",
    "clf_neigh.fit(X_new,np.ravel(Y))\n",
    "clf_neigh.score(X_new_2018, Y_2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submission ID</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>3.15    4.2    4.65</td>\n",
       "      <td>Binaural Speech Intelligibility Estimation Usi...</td>\n",
       "      <td>We attempted to estimate the speech intelligib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>5.25    4.95    5.05    4.95</td>\n",
       "      <td>Real-Time Scoring of an Oral Reading Assessmen...</td>\n",
       "      <td>We discuss the real-time scoring logic for a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>5.2    4.9    5.15    4.8</td>\n",
       "      <td>Conditional End-to-End Audio Transformations</td>\n",
       "      <td>We present an end-to-end method for transformi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>2.05    4.7    5.9    5.7</td>\n",
       "      <td>Speech Recognition for Medical Conversations</td>\n",
       "      <td>In this paper we document our experiences with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>5    4.9    4.75    4.75</td>\n",
       "      <td>Improved Supervised Locality Preserving Projec...</td>\n",
       "      <td>A Supervised Locality Preserving Projection (S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Submission ID                            Scores  \\\n",
       "0             27           3.15    4.2    4.65       \n",
       "1             34  5.25    4.95    5.05    4.95       \n",
       "2             38     5.2    4.9    5.15    4.8       \n",
       "3             40     2.05    4.7    5.9    5.7       \n",
       "4             41      5    4.9    4.75    4.75       \n",
       "\n",
       "                                               Title  \\\n",
       "0  Binaural Speech Intelligibility Estimation Usi...   \n",
       "1  Real-Time Scoring of an Oral Reading Assessmen...   \n",
       "2       Conditional End-to-End Audio Transformations   \n",
       "3       Speech Recognition for Medical Conversations   \n",
       "4  Improved Supervised Locality Preserving Projec...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  We attempted to estimate the speech intelligib...  \n",
       "1  We discuss the real-time scoring logic for a s...  \n",
       "2  We present an end-to-end method for transformi...  \n",
       "3  In this paper we document our experiences with...  \n",
       "4  A Supervised Locality Preserving Projection (S...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading 2017 scores\n",
    "Accept_2018=pandas.read_excel('./acceptedPaperDetails_2018.xlsx');\n",
    "Reject_2018=pandas.read_excel('./rejectPaperDetails_2018.xlsx');\n",
    "\n",
    "Accept_2018.head()\n",
    "# Reject_2018.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 749 entries, 0 to 748\n",
      "Data columns (total 6 columns):\n",
      "Submission ID    749 non-null int64\n",
      "Scores           749 non-null object\n",
      "Title            749 non-null object\n",
      "Abstract         749 non-null object\n",
      "result           749 non-null float64\n",
      "mean             749 non-null float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 35.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 582 entries, 0 to 581\n",
      "Data columns (total 6 columns):\n",
      "Submission ID    582 non-null int64\n",
      "Scores           582 non-null object\n",
      "Title            582 non-null object\n",
      "Abstract         582 non-null object\n",
      "result           582 non-null float64\n",
      "mean             582 non-null float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 27.4+ KB\n"
     ]
    }
   ],
   "source": [
    "Accept_2018[\"result\"]=pandas.Series(np.zeros(len(Accept_2018),dtype=float)) \n",
    "Accept_2018[\"mean\"]=pandas.Series(np.zeros(len(Accept_2018),dtype=float)) \n",
    "Accept_2018.info()\n",
    "Reject_2018[\"result\"]=pandas.Series(np.ones(len(Reject_2018),dtype=float)) \n",
    "Reject_2018[\"mean\"]=pandas.Series(np.zeros(len(Reject_2018),dtype=float)) \n",
    "Reject_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2018 = Accept_2018.append(Reject_2018, ignore_index=True)\n",
    "def text_toscore(temp):\n",
    "    temp = temp.split()\n",
    "    score = [float(i) for i in temp]\n",
    "    m = np.mean(score)\n",
    "    s = np.std(score)\n",
    "    return score,m,s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1331 entries, 1033 to 254\n",
      "Data columns (total 6 columns):\n",
      "Submission ID    1331 non-null int64\n",
      "Scores           1331 non-null object\n",
      "Title            1331 non-null object\n",
      "Abstract         1331 non-null object\n",
      "result           1331 non-null float64\n",
      "mean             1331 non-null float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 72.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submission ID</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>result</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1760</td>\n",
       "      <td>5.85    5.2    5.8</td>\n",
       "      <td>Picture Naming or Word Reading: Does the Modal...</td>\n",
       "      <td>Auditory-motor adaptation and transfer paradig...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51</td>\n",
       "      <td>5.9    5.75    5.1    5.9</td>\n",
       "      <td>The INTERSPEECH 2018 Computational Paralinguis...</td>\n",
       "      <td>The INTERSPEECH 2018 Computational Paralinguis...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1384</td>\n",
       "      <td>6    5.95    5.8    5</td>\n",
       "      <td>Articulation Rate as a Speaker Discriminant in...</td>\n",
       "      <td>Identifying speech parameters that have both a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2284</td>\n",
       "      <td>5.85    5.6    5.9    5.85</td>\n",
       "      <td>Recognizing Overlapped Speech in Meetings: a M...</td>\n",
       "      <td>The goal of this work is to develop a meeting ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1392</td>\n",
       "      <td>5.75    6    5.9    5.75</td>\n",
       "      <td>Cold Fusion: Training Seq2Seq Models Together ...</td>\n",
       "      <td>Sequence-to-sequence (Seq2Seq) models with att...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Submission ID                          Scores  \\\n",
       "431           1760          5.85    5.2    5.8       \n",
       "12              51   5.9    5.75    5.1    5.9       \n",
       "250           1384       6    5.95    5.8    5       \n",
       "628           2284  5.85    5.6    5.9    5.85       \n",
       "254           1392    5.75    6    5.9    5.75       \n",
       "\n",
       "                                                 Title  \\\n",
       "431  Picture Naming or Word Reading: Does the Modal...   \n",
       "12   The INTERSPEECH 2018 Computational Paralinguis...   \n",
       "250  Articulation Rate as a Speaker Discriminant in...   \n",
       "628  Recognizing Overlapped Speech in Meetings: a M...   \n",
       "254  Cold Fusion: Training Seq2Seq Models Together ...   \n",
       "\n",
       "                                              Abstract  result      mean  \n",
       "431  Auditory-motor adaptation and transfer paradig...     0.0  5.616667  \n",
       "12   The INTERSPEECH 2018 Computational Paralinguis...     0.0  5.662500  \n",
       "250  Identifying speech parameters that have both a...     0.0  5.687500  \n",
       "628  The goal of this work is to develop a meeting ...     0.0  5.800000  \n",
       "254  Sequence-to-sequence (Seq2Seq) models with att...     0.0  5.850000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in data_2018.index:\n",
    "    #print(i)\n",
    "    temp = data_2018.iloc[i][\"Scores\"]\n",
    "    #print(temp)\n",
    "    score,m,s = text_toscore(temp) \n",
    "    #print(m)\n",
    "    data_2018.at[i, 'mean'] = m\n",
    "    \n",
    "data_2018 = data_2018.fillna(\"\")\n",
    "Data_2018 = data_2018.sort_values(by=['mean'])\n",
    "Data_2018.info()\n",
    "Data_2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_2018.to_csv('sorted_2018results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_scores_2018=np.zeros((len(Data_2018),6)) \n",
    "output_class_2018=np.zeros((len(Data_2018),))\n",
    "count = 0\n",
    "for i in range(len(Data_2018)):\n",
    "    #print(i)\n",
    "    temp = Data_2018.iloc[i][\"Scores\"]\n",
    "    result = Data_2018.iloc[i][\"result\"]\n",
    "    #print(temp)\n",
    "    score,m,s = text_toscore(temp) \n",
    "    #print(m)\n",
    "    input_scores_2018[count,0:len(score)]=score\n",
    "    output_class_2018[count] = result\n",
    "    count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1331, 6)\n",
      "(1331,)\n"
     ]
    }
   ],
   "source": [
    "print(input_scores_2018.shape)\n",
    "print(output_class_2018.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scores_covertion(X_scores):\n",
    "    X_new = np.zeros((len(X_scores),11))\n",
    "    count = 0\n",
    "    addon = 0\n",
    "    for i in X_scores:\n",
    "        \n",
    "        X_new[count,addon+0] = i[i.nonzero()].mean()/6\n",
    "        X_new[count,addon+1] = i[i.nonzero()].std()/6\n",
    "        temp = np.ptp(i[i.nonzero()])\n",
    "        if(temp == 0):\n",
    "            X_new[count,addon+2] = np.max(X_new[:,addon+2])\n",
    "        else:\n",
    "            X_new[count,addon+2] = 6*X_new[count,addon+0]*(1.0/(temp))\n",
    "        X_new[count,addon+3] = np.max(i[i.nonzero()])/6\n",
    "        X_new[count,addon+4] = np.min(i[i.nonzero()])/6\n",
    "        a = i\n",
    "        X_new[count,addon+5] = np.sum(np.logical_and(a>0.1, a<=1))\n",
    "        X_new[count,addon+6] = np.sum(np.logical_and(a>1, a<=2))\n",
    "        X_new[count,addon+7] = np.sum(np.logical_and(a>2, a<=3))\n",
    "        X_new[count,addon+8] = np.sum(np.logical_and(a>3, a<=4))\n",
    "        X_new[count,addon+9] = np.sum(np.logical_and(a>4, a<=5))\n",
    "        X_new[count,addon+10] = np.sum(np.logical_and(a>5, a<=6))\n",
    "        \n",
    "        count +=1\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83541667 0.11966025 3.1328125  0.96666667 0.7        0.\n",
      " 0.         0.         0.         2.         2.        ]\n"
     ]
    }
   ],
   "source": [
    "X_2018 = scores_covertion(input_scores_2018)\n",
    "print(X_2018[1201])\n",
    "# np.mean(X_2017,axis=0)\n",
    "mean_2018 = np.mean(X_2018[:,2],axis = 0)\n",
    "std_2018 = np.std(X_2018[:,2],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.65, 4.2 , 4.4 , 5.8 , 0.  , 0.  ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_scores_2018[1201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_2017' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-44f022625c00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_2018\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_2018\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean_2017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstd_2017\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_2017' is not defined"
     ]
    }
   ],
   "source": [
    "X_2018[:,2] = (X_2018[:,2]-mean_2017)/std_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9da54ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(X_2018[:,2], bins=100)\n",
    "#plt.hist(X_new[750:-1,7], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.531499107632811"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
